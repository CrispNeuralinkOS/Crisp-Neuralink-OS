//! MEDICAL-GRADE NEURAL ATTENTION SYSTEM WITH CLOSED-LOOP ADAPTATION
//! kurt kristoff nitsch, licence 2025: Apache-2.0
//! Features:
//! - Real-time neural signal processing
//! - Adaptive attention mechanisms
//! - Triple-redundant safety systems
//! - Closed-loop learning with performance optimization

#![deny(unsafe_code)]
#![feature(portable_simd)]

use std::{
    sync::{
        atomic::{AtomicBool, AtomicU64, Ordering},
        Arc, Mutex,
    },
    time::{Duration, Instant},
    simd::f32x8,
    collections::VecDeque,
};
use nalgebra::{DMatrix, DVector, DVectorSlice};
use ndarray::{Array3, Axis};
use thiserror::Error;
use rand::Rng;
use serde::{Serialize, Deserialize};

// ======================
// 1. CORE DATA STRUCTURES
// ======================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NeuralSignal {
    pub timestamp: Instant,
    pub raw_data: DVector<f32>,
    pub filtered_data: DVector<f32>,
    pub spike_times: Vec<f32>,
    pub frequency_bands: FrequencyBands,
    pub source_location: Point3D,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FrequencyBands {
    pub delta: f32,
    pub theta: f32,
    pub alpha: f32,
    pub beta: f32,
    pub gamma: f32,
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct Point3D {
    pub x: f32,
    pub y: f32,
    pub z: f32,
}

impl Point3D {
    pub fn origin() -> Self {
        Self { x: 0.0, y: 0.0, z: 0.0 }
    }

    pub fn distance(&self, other: &Point3D) -> f32 {
        ((self.x - other.x).powi(2) + 
        (self.y - other.y).powi(2) + 
        (self.z - other.z).powi(2)).sqrt()
    }

    pub fn to_vector(&self) -> DVector<f32> {
        DVector::from_vec(vec![self.x, self.y, self.z])
    }
}

// ======================
// 2. ATTENTION MECHANISMS
// ======================

/// Multi-scale attention controller
pub struct AttentionController {
    pub temporal: TemporalAttention,
    pub spatial: SpatialAttention,
    pub feature: FeatureAttention,
    pub fusion_weights: DMatrix<f32>,
    pub safety_monitor: SafetyMonitor,
    pub adaptation_engine: AdaptationEngine,
    pub config: AttentionConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AttentionConfig {
    pub temporal_window_ms: u32,
    pub spatial_resolution: (u32, u32, u32),
    pub max_stimulation_mA: f32,
    pub min_feature_activity: f32,
    pub learning_rate: f32,
    pub stability_threshold: f32,
}

impl AttentionController {
    pub fn new(config: AttentionConfig) -> Self {
        let temporal_size = (config.temporal_window_ms * 10) as usize; // 10kHz sampling
        let spatial_size = (
            config.spatial_resolution.0 as usize,
            config.spatial_resolution.1 as usize,
            config.spatial_resolution.2 as usize,
        );
        
        Self {
            temporal: TemporalAttention::new(temporal_size),
            spatial: SpatialAttention::new(spatial_size, config.max_stimulation_mA),
            feature: FeatureAttention::new(config.min_feature_activity),
            fusion_weights: DMatrix::identity(
                temporal_size + 
                spatial_size.0 * spatial_size.1 * spatial_size.2 + 
                5, // Frequency bands
            ),
            safety_monitor: SafetyMonitor::new(),
            adaptation_engine: AdaptationEngine::new(config.learning_rate),
            config,
        }
    }

    /// Process neural signal through attention hierarchy
    pub fn process(&mut self, signal: &NeuralSignal) -> Result<AttentionOutput, AttentionError> {
        // 1. Temporal attention
        let temporal_output = self.temporal.process(&signal.filtered_data)?;
        
        // 2. Spatial attention
        let spatial_output = self.spatial.focus(&signal.source_location)?;
        
        // 3. Feature attention
        let feature_output = self.feature.process(&signal.frequency_bands)?;
        
        // 4. Fuse outputs
        let fused = temporal_output
            .stack(&spatial_output.to_vector())
            .stack(&feature_output);
        
        let output = &self.fusion_weights * fused;
        
        // 5. Safety validation
        self.safety_monitor.validate(&output, &signal)?;
        
        // 6. Adaptation
        if self.config.learning_rate > 0.0 {
            self.adaptation_engine.update(&signal, &output);
        }
        
        Ok(AttentionOutput {
            attention_weights: output,
            focus_location: signal.source_location,
            processing_latency: signal.timestamp.elapsed(),
        })
    }

    /// Apply learned adaptations
    pub fn apply_adaptations(&mut self) -> Result<(), AttentionError> {
        let adaptations = self.adaptation_engine.generate_updates();
        
        self.temporal.adapt(&adaptations.temporal)?;
        self.spatial.adapt(&adaptations.spatial)?;
        self.feature.adapt(&adaptations.feature)?;
        
        // Update fusion weights
        self.fusion_weights += &adaptations.fusion;
        
        Ok(())
    }
}

// ======================
// 3. TEMPORAL ATTENTION
// ======================

/// Gated recurrent attention with adaptive time constants
pub struct TemporalAttention {
    pub input_gate: DMatrix<f32>,
    pub forget_gate: DMatrix<f32>,
    pub output_gate: DMatrix<f32>,
    pub time_constants: DVector<f32>,
    pub state: DVector<f32>,
    pub safety_lock: Arc<AtomicBool>,
}

impl TemporalAttention {
    pub fn new(size: usize) -> Self {
        Self {
            input_gate: DMatrix::identity(size, size),
            forget_gate: DMatrix::from_fn(size, size, |i,j| 0.5 + 0.1 * (i as f32 - j as f32).abs()),
            output_gate: DMatrix::identity(size, size),
            time_constants: DVector::from_element(size, 10.0), // 10ms default
            state: DVector::zeros(size),
            safety_lock: Arc::new(AtomicBool::new(false)),
        }
    }

    pub fn process(&mut self, input: &DVector<f32>) -> Result<DVector<f32>, AttentionError> {
        if self.safety_lock.load(Ordering::SeqCst) {
            return Err(AttentionError::SafetyLockEngaged);
        }

        // SIMD-optimized gating
        let dt = self.time_constants.map(|tau| 1.0 - (-0.1/tau).exp());
        
        // Input gate
        let input_gated = self.gate_transform(&self.input_gate, input, &dt, GateType::Input)?;
        
        // Forget gate
        let memory = self.gate_transform(&self.forget_gate, &self.state, &dt, GateType::Forget)?;
        
        // Update state
        self.state = input_gated.component_mul(&memory);
        
        // Output gate
        let output = self.gate_transform(&self.output_gate, &self.state, &dt, GateType::Output)?;
        
        Ok(output.normalize())
    }

    pub fn adapt(&mut self, adaptation: &TemporalAdaptation) -> Result<(), AttentionError> {
        if self.safety_lock.load(Ordering::SeqCst) {
            return Err(AttentionError::SafetyLockEngaged);
        }

        // Apply weight updates with safety constraints
        self.input_gate += &adaptation.input_delta;
        self.forget_gate += &adaptation.forget_delta;
        self.output_gate += &adaptation.output_delta;
        
        // Normalize gates
        self.input_gate = self.input_gate.map(|x| x.clamp(0.0, 1.0));
        self.forget_gate = self.forget_gate.map(|x| x.clamp(0.0, 1.0));
        self.output_gate = self.output_gate.map(|x| x.clamp(-1.0, 1.0));
        
        Ok(())
    }

    #[inline(always)]
    fn gate_transform(&self, 
        weights: &DMatrix<f32>,
        input: &DVector<f32>,
        dt: &DVector<f32>,
        gate_type: GateType,
    ) -> Result<DVector<f32>, AttentionError> {
        let mut output = DVector::zeros(input.len());
        
        // SIMD-optimized matrix-vector multiply
        for (i, row) in weights.row_iter().enumerate() {
            let mut sum = f32x8::splat(0.0);
            let chunks = row.as_slice().chunks_exact(8);
            
            for (j, chunk) in chunks.enumerate() {
                let input_chunk = f32x8::from_slice(&input.as_slice()[j*8..j*8+8]);
                let weight_chunk = f32x8::from_slice(chunk);
                sum += weight_chunk * input_chunk;
            }
            
            let scalar_sum = sum.reduce_sum();
            output[i] = match gate_type {
                GateType::Input => sigmoid(scalar_sum * dt[i]),
                GateType::Forget => (-scalar_sum * dt[i]).exp(),
                GateType::Output => scalar_sum.tanh(),
            };
        }
        
        Ok(output)
    }
}

// ======================
// 4. SPATIAL ATTENTION
// ======================

/// MRI-constrained spatial attention
pub struct SpatialAttention {
    pub focus_map: Array3<f32>,
    pub prohibited_zones: Array3<bool>,
    pub max_intensity: f32,
    pub current_focus: Point3D,
    pub safety_monitor: Arc<Mutex<SpatialSafety>>,
}

impl SpatialAttention {
    pub fn new(dimensions: (usize, usize, usize), max_intensity: f32) -> Self {
        Self {
            focus_map: Array3::zeros(dimensions),
            prohibited_zones: Array3::from_elem(dimensions, false),
            max_intensity,
            current_focus: Point3D::origin(),
            safety_monitor: Arc::new(Mutex::new(SpatialSafety::new())),
        }
    }

    pub fn focus(&mut self, target: &Point3D, intensity: f32) -> Result<DVector<f32>, AttentionError> {
        // Validate intensity
        if intensity > self.max_intensity {
            return Err(AttentionError::IntensityLimitExceeded);
        }

        // Check safety
        let mut safety = self.safety_monitor.lock().unwrap();
        if !safety.validate_location(target) {
            return Err(AttentionError::ProhibitedZone);
        }

        // Update focus
        self.current_focus = *target;
        self.focus_map = self.gaussian_3d(target, intensity);
        
        // Zero out prohibited zones
        self.focus_map.zip_mut_with(&self.prohibited_zones, |v, &p| {
            if p { *v = 0.0 }
        });

        Ok(DVector::from_vec(self.focus_map.iter().cloned().collect()))
    }

    pub fn adapt(&mut self, adaptation: &SpatialAdaptation) -> Result<(), AttentionError> {
        let new_focus = Point3D {
            x: self.current_focus.x + adaptation.dx,
            y: self.current_focus.y + adaptation.dy,
            z: self.current_focus.z + adaptation.dz,
        };

        // Validate new focus
        let safety = self.safety_monitor.lock().unwrap();
        if !safety.validate_location(&new_focus) {
            return Err(AttentionError::ProhibitedZone);
        }

        self.current_focus = new_focus;
        Ok(())
    }

    fn gaussian_3d(&self, center: &Point3D, sigma: f32) -> Array3<f32> {
        Array3::from_shape_fn(self.focus_map.dim(), |(x,y,z)| {
            let dx = x as f32 - center.x;
            let dy = y as f32 - center.y;
            let dz = z as f32 - center.z;
            let dist_sq = dx*dx + dy*dy + dz*dz;
            (-dist_sq / (2.0 * sigma * sigma)).exp()
        })
    }
}

// ======================
// 5. FEATURE ATTENTION
// ======================

/// Context-aware feature selection
pub struct FeatureAttention {
    pub weights: DMatrix<f32>,
    pub stability_factor: f32,
    pub min_activity: f32,
    pub learning_enabled: bool,
}

impl FeatureAttention {
    pub fn new(min_activity: f32) -> Self {
        Self {
            weights: DMatrix::identity(5, 5), // 5 frequency bands
            stability_factor: 0.8,
            min_activity,
            learning_enabled: true,
        }
    }

    pub fn process(&mut self, features: &FrequencyBands) -> Result<DVector<f32>, AttentionError> {
        let input = DVector::from_vec(vec![
            features.delta,
            features.theta,
            features.alpha,
            features.beta,
            features.gamma,
        ]);

        // Apply attention weights
        let mut output = &self.weights * &input;
        
        // Stability modulation
        output = output.map(|x| x * self.stability_factor);
        
        // Softmax with minimum activity
        Ok(softmax_with_min(&output, self.min_activity))
    }

    pub fn adapt(&mut self, adaptation: &FeatureAdaptation) -> Result<(), AttentionError> {
        if self.learning_enabled {
            self.weights += &adaptation.weight_delta;
            self.stability_factor = (self.stability_factor + adaptation.stability_delta)
                .clamp(0.1, 1.0);
        }
        Ok(())
    }
}

// ======================
// 6. ADAPTATION ENGINE
// ======================

/// Closed-loop performance optimization
pub struct AdaptationEngine {
    pub learning_rate: f32,
    pub performance_history: VecDeque<f32>,
    pub error_history: VecDeque<f32>,
    pub adaptation_buffer: Vec<AdaptationUpdate>,
}

impl AdaptationEngine {
    pub fn new(learning_rate: f32) -> Self {
        Self {
            learning_rate,
            performance_history: VecDeque::with_capacity(100),
            error_history: VecDeque::with_capacity(100),
            adaptation_buffer: Vec::new(),
        }
    }

    pub fn update(&mut self, signal: &NeuralSignal, output: &DVector<f32>) {
        // Track performance metrics
        let performance = self.calculate_performance(signal, output);
        self.performance_history.push_back(performance);
        if self.performance_history.len() > 100 {
            self.performance_history.pop_front();
        }

        // Track errors
        let error = self.calculate_error(signal, output);
        self.error_history.push_back(error);
        if self.error_history.len() > 100 {
            self.error_history.pop_front();
        }

        // Generate new adaptations
        self.generate_adaptations();
    }

    pub fn generate_updates(&mut self) -> Vec<AdaptationUpdate> {
        self.adaptation_buffer.drain(..).collect()
    }

    fn calculate_performance(&self, signal: &NeuralSignal, output: &DVector<f32>) -> f32 {
        // Placeholder - would use task-specific metrics
        0.8 // Example value
    }

    fn calculate_error(&self, signal: &NeuralSignal, output: &DVector<f32>) -> f32 {
        // Placeholder - would compare to desired output
        0.1 // Example value
    }

    fn generate_adaptations(&mut self) {
        // Placeholder - sophisticated adaptation logic would go here
        let update = AdaptationUpdate {
            temporal: TemporalAdaptation::default(),
            spatial: SpatialAdaptation::default(),
            feature: FeatureAdaptation::default(),
            fusion: DMatrix::zeros(1, 1), // Example size
        };
        self.adaptation_buffer.push(update);
    }
}

// ======================
// 7. SAFETY SYSTEMS
// ======================

/// Triple-redundant safety monitoring
pub struct SafetyMonitor {
    pub rule_based: RuleBasedMonitor,
    pub ml_based: MLMonitor,
    pub hardware: HardwareMonitor,
    pub violation_count: Arc<AtomicU64>,
}

impl SafetyMonitor {
    pub fn new() -> Self {
        Self {
            rule_based: RuleBasedMonitor::new(),
            ml_based: MLMonitor::new(),
            hardware: HardwareMonitor::new(),
            violation_count: Arc::new(AtomicU64::new(0)),
        }
    }

    pub fn validate(&self, output: &DVector<f32>, signal: &NeuralSignal) -> Result<(), AttentionError> {
        // Rule-based checks
        if let Err(e) = self.rule_based.check(output, signal) {
            self.violation_count.fetch_add(1, Ordering::SeqCst);
            return Err(e);
        }

        // ML anomaly detection
        if let Err(e) = self.ml_based.check(output, signal) {
            self.violation_count.fetch_add(1, Ordering::SeqCst);
            return Err(e);
        }

        // Hardware validation
        if let Err(e) = self.hardware.check(output) {
            self.violation_count.fetch_add(1, Ordering::SeqCst);
            return Err(e);
        }

        Ok(())
    }
}

// ======================
// 8. SUPPORTING TYPES
// ======================

#[derive(Debug, Error)]
pub enum AttentionError {
    #[error("Safety lock engaged")]
    SafetyLockEngaged,
    #[error("Intensity limit exceeded")]
    IntensityLimitExceeded,
    #[error("Prohibited zone violation")]
    ProhibitedZone,
    #[error("Temporal instability detected")]
    TemporalInstability,
    #[error("Feature attention failure")]
    FeatureAttentionFailed,
    #[error("Adaptation error: {0}")]
    AdaptationFailed(String),
}

#[derive(Debug, Clone)]
pub struct AttentionOutput {
    pub attention_weights: DVector<f32>,
    pub focus_location: Point3D,
    pub processing_latency: Duration,
}

#[derive(Debug, Default)]
pub struct TemporalAdaptation {
    pub input_delta: DMatrix<f32>,
    pub forget_delta: DMatrix<f32>,
    pub output_delta: DMatrix<f32>,
}

#[derive(Debug, Default)]
pub struct SpatialAdaptation {
    pub dx: f32,
    pub dy: f32,
    pub dz: f32,
}

#[derive(Debug, Default)]
pub struct FeatureAdaptation {
    pub weight_delta: DMatrix<f32>,
    pub stability_delta: f32,
}

#[derive(Debug)]
pub struct AdaptationUpdate {
    pub temporal: TemporalAdaptation,
    pub spatial: SpatialAdaptation,
    pub feature: FeatureAdaptation,
    pub fusion: DMatrix<f32>,
}

#[derive(Debug)]
enum GateType {
    Input,
    Forget,
    Output,
}

// Helper functions
#[inline]
fn sigmoid(x: f32) -> f32 {
    1.0 / (1.0 + (-x).exp())
}

#[inline]
fn softmax_with_min(vec: &DVector<f32>, min: f32) -> DVector<f32> {
    let max = vec.max();
    let exp_sum: f32 = vec.iter().map(|&x| (x - max).exp()).sum();
    vec.map(|&x| ((x - max).exp() / exp_sum).max(min))
}
